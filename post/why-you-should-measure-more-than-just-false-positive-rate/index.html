<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Why you should measure more than just false-positive rate | bradleyjkemp</title>

<meta name="keywords" content="" />
<meta name="description" content="Other titles:
 Why you need to measure an alert&rsquo;s benign rate, not just false-positive rate Why you need to measure benign rate, not just false-positive rate for alerts Not all false-positive alerts are bad. Why you need to measure malicious-rate too. Not all high false-positive rate alerts are noisy  False-positive rate is a great metric to use while developing detection rules but, once a rule is in production, things get more complicated.">
<meta name="author" content="Bradley Kemp">
<link rel="canonical" href="https://bradleyjkemp.dev/post/why-you-should-measure-more-than-just-false-positive-rate/" />
<link href="https://bradleyjkemp.dev/assets/css/stylesheet.min.1a469c0f608c29f4bdf84ed8475869fd7615a9064b4ee7f3e030499826391c21.css" integrity="sha256-GkacD2CMKfS9&#43;E7YR1hp/XYVqQZLTufz4DBJmCY5HCE=" rel="preload stylesheet"
    as="style">

<link rel="icon" href="https://bradleyjkemp.dev/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://bradleyjkemp.dev/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://bradleyjkemp.dev/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://bradleyjkemp.dev/apple-touch-icon.png">
<link rel="mask-icon" href="https://bradleyjkemp.dev/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<meta name="generator" content="Hugo 0.79.0" />
<link rel="webmention" href="https://webmention.io/bradleyjkemp.dev/webmention" />
<link rel="pingback" href="https://webmention.io/bradleyjkemp.dev/xmlrpc" />



<!-- plausible.io section --><!-- Preconnect to required origins -->
<link rel="preconnect" href='https://stats.bradleyjkemp.dev'>

    
    
        
            
                
<script async defer data-domain="bradleyjkemp.dev" src='https://stats.bradleyjkemp.dev/js/plausible.js'></script>

        
        
        
<script>window.plausible = window.plausible || function() { (window.plausible.q = window.plausible.q || []).push(arguments) }</script>

        
<!-- Specific script for plausible.io -->
        
        
<script>
     
    
     
     
</script>

        
<!-- If you are using Content-Security-Policy, do not forget to add this code to your CSP : 
  script-src 'unsafe-inline' https://stats.bradleyjkemp.dev
  connect-src 'unsafe-inline' https://stats.bradleyjkemp.dev
  or just add the partial 'plausible.csp.html' to those 2 csp directive in your 'index.headers' file
-->

        
<!-- End of plausible.io section -->
<meta property="og:title" content="Why you should measure more than just false-positive rate" />
<meta property="og:description" content="Other titles:
 Why you need to measure an alert&rsquo;s benign rate, not just false-positive rate Why you need to measure benign rate, not just false-positive rate for alerts Not all false-positive alerts are bad. Why you need to measure malicious-rate too. Not all high false-positive rate alerts are noisy  False-positive rate is a great metric to use while developing detection rules but, once a rule is in production, things get more complicated." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://bradleyjkemp.dev/post/why-you-should-measure-more-than-just-false-positive-rate/" />
<meta property="article:published_time" content="2021-01-30T00:00:00+00:00" />
<meta property="article:modified_time" content="2021-01-30T00:00:00+00:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Why you should measure more than just false-positive rate"/>
<meta name="twitter:description" content="Other titles:
 Why you need to measure an alert&rsquo;s benign rate, not just false-positive rate Why you need to measure benign rate, not just false-positive rate for alerts Not all false-positive alerts are bad. Why you need to measure malicious-rate too. Not all high false-positive rate alerts are noisy  False-positive rate is a great metric to use while developing detection rules but, once a rule is in production, things get more complicated."/>

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Why you should measure more than just false-positive rate",
  "name": "Why you should measure more than just false-positive rate",
  "description": "Other titles:\n Why you need to measure an alert\u0026amp;rsquo;s benign rate, not just false-positive rate Why you need to measure benign rate, not just false-positive rate for alerts Not ‚Ä¶",
  "keywords": [
    
  ],
  "articleBody": "Other titles:\n Why you need to measure an alert‚Äôs benign rate, not just false-positive rate Why you need to measure benign rate, not just false-positive rate for alerts Not all false-positive alerts are bad. Why you need to measure malicious-rate too. Not all high false-positive rate alerts are noisy  False-positive rate is a great metric to use while developing detection rules but, once a rule is in production, things get more complicated.\nBut before we go any further, why measure detection rule performance in the first place? Unless you‚Äôve got an unlimited budget for SOC analysts, you need to decide which security alerts are valuable enough to review and which you‚Äôre going to ignore.\nYou might be making this decision explicitly (just dropping unreviewed alerts at the end of the day) or implicitly\nEven if you‚Äôre thinking ‚Äúbut we don‚Äôt ignore any alerts, we review them all!‚Äù, However, I‚Äôm sure there‚Äôs more detection rules you could add and if you‚Äôre choosing not to, you‚Äôre choosing to ignore those alerts. There‚Äôs always more detection rules you can add and if you‚Äôre choosing to skip these new rules, you‚Äôre choosing to ignore these alerts.\nThe hard part of detection engineering is tuning alerts so reviewing them is a valuable use of time. Every alert has an attached opportunity cost. By choosing to review it, you‚Äôre implicitly choosing not to review another alert.\nIt‚Äôs therefore vital to be able to understand which alerts are valuable, which need tuning, and which just need to be scrapped because they‚Äôre a time sink. How? Metrics.\nThe problem with only measuring false-positive rate Let‚Äôs take an example detection rule that alerts whenever someone SSH‚Äôs into a production server‚Äîthe goal being to catch an attacker stealing or tampering with production data. Hopefully you don‚Äôt have attackers accessing your servers on a regular basis‚Äîif so, this post isn‚Äôt for you‚Äîso most of the alerts are going to be when an on-call engineer needs to SSH into production to fix an incident. An alert reviewer handles this by checking that, yes, there was an ongoing incident and the engineer that triggered the alert was responding.\nBut, how should they close the alert? There‚Äôs no impact so perhaps they should mark it as a false-positive? If they do, your stats will show this alert having an almost 100% false-positive rate.\nIn comparison, lets imagine a detection rule that alerts on newly registered domain names which are similar to your company‚Äôs name. Depending on your company this could generate lots of alerts for domains which are closed as obviously harmless false-positives. A rule this simple is not going to be useful for Apple or Three or any other noun-named company. If that‚Äôs you, your stats will show that this alert also has a very high false-positive rate.\nBut something‚Äôs wrong here. The SSH alert actually does provide some value (verifying that on-call engineers aren‚Äôt abusing their systems access) whereas the harmless domain name alerts are providing no value. Despite this, just scoring them on false-positive rate could make them look equally bad.\n// The reason is because false-positive vs true-positive is a false dichotomy‚Äîwe need more ‚Äúdimensions‚Äù to our rating.\nMeasuring a second dimension: maliciousness Is a detection rule‚Äôs goal to detect security incidents? Actually no, not really. That‚Äôs the goal of an entire suite of detections rules plus a team who review the alerts. An individual rule should have an extremely specific aim for what it detects, for example:\n Attackers are likely to steal data so alert on SSH access to our production servers. Phishing sites are usually hosted on lookalike domains so alert on newly registered domains which are similar to our company‚Äôs name. No legitimate users should be accessing a honeypot fileserver so alert on any interaction with it.  Whether an alert fired correctly (i.e. in line with the rule‚Äôs aim) is entirely separate from whether it detected malicious behaviour.\nIf your honeypot fileserver downloads a software update and an alert fires, that‚Äôs a false-positive: a self-update shouldn‚Äôt have been detected as a user interacting with the honeypot.\nBut, the alert that fires when a curious user stumbles across the honeypot fileserver is a true-positive. While the behaviour may not have been malicious, the alert did fire correctly.\nSo what happens if we separately measure alert correctness and maliciousness? You get something like this üëáüèª\nUnsurprisingly, we get a much more nuanced picture. No longer the false dichotomy between high-signal alert and noisy alert. Instead a third type of alerts appears: the assurance alert.\nLet‚Äôs go over the different quadrants.\n‚ÜóÔ∏è High signal alerts üö® // TODO: alerts or rules? This one should be obvious, detection rules with high true-positive rate and high malicious rate are your gold standard. They produce really high signal alerts that you definitely shouldn‚Äôt be ignoring.\nHigh signal alerts are going to include:\n The catastrophic stuff e.g. a binary is running whose hash matches known malware. // TODO The impossible stuff e.g. a honeypot gets triggered on your internal network.   #callout { background: var(--code-bg); padding: 1.5em 1.25em; border-radius: 3px; display: flex; flex-direction: row; margin-bottom: 20px; } #callout-inner { margin-left: 1em; } @media (max-width: 767px) { #callout { padding: 1.5em 0.75em 1.5em 0.6em; } #callout-inner { margin-left: 0.5em; } }  üçØ Honeypots are a great example of high signal alerts with really low false-positive rates. Read my previous post to find out how honeypots work so well.   ‚ÜòÔ∏è Assurance alerts ‚úÖ Detection rules with a high true-positive rate but high benign rate are ‚Äúassurance‚Äù alerts.\nThink of all the ‚Äúyou‚Äôve signed in on a new device‚Äù or ‚Äúthe email address on your account has been changed‚Äù emails you‚Äôve received. They‚Äôre always accurate (true positives) but they‚Äôre also almost always benign because you‚Äôve triggered them yourself. These are assurance alerts.\nThe purpose of assurance alerts isn‚Äôt to catch an attacker every time the alert fires, it‚Äôs to give you confidence that an attacker can‚Äôt do something without you knowing.\nAssurance alerts are going to include things like:\n Someone has used a break-glass procedure, only intended for use during incidents. You need to verify it‚Äôs been used appropriately. Someone has been granted administrative permissions. You need to check they‚Äôre supposed to have these new, powerful permissions. A binary has done something weird TODO  ‚ÜôÔ∏è Noisy alerts üîá Detection rules with a high false-positive rate and a high benign rate are the classic ‚Äúnoisy‚Äù alert.\nNoisy alerts just plain suck. They‚Äôre not worth the time spent reviewing them.\n‚ÜñÔ∏è Dumb luck alerts üçÄ The fourth quadrant, with a high false-positive rate and miraculously high malicious rate, probably doesn‚Äôt exist.\nIf you have a detection rule that regularly mis-fires but on investigation you still find malicious behaviour then either:\n You need to stop reading this post and go evict the 1000 different attackers you have in your system. You‚Äôre investigating alerts way too deeply. Go update LinkedIn with your new title ‚ÄúThreat Hunter‚Äù and collect a 50% pay rise.  Using these metrics to improve our alerts So how do we use these metrics to make better decisions about which alerts to review?\nImproving Assurance alerts ‚úÖ Assurance alerts are a sore spot. Although they provide some value, reviewing them feels very unproductive‚Äîthey mostly just require verifying that the event was expected.\nHowever, it‚Äôs a tough decision to get rid of them. These alerts exist because the consequences of a true-positive, malicious alert are very bad. Personally, would you be comfortable not being notified whenever your account was signed into on a new device?\nUse MFA to shift the burden A lot of the pain of assurance alerts arises because the people reviewing the alerts don‚Äôt have the same context as the people causing the alerts.\nWhen reviewing an alert for an on-call engineer accessing to a production server, the reviewer has to go work out: what incident might this be related to? does that incident actually require accessing production? While these answers are obvious to the person who triggered the alert, they‚Äôre not so easy for the alert reviewer.\nIt‚Äôd be great if the person generating the alert could also review it. They‚Äôve got all the context and so can easily affirm, yes I did just do X. Obviously, this needs to be done carefully‚Äîit‚Äôs no use if an attacker can SSH into production and then just close the alert themself.\nThat‚Äôs where multi-factor authentication can help. If the on-call engineer has an authentication factor that‚Äôs entirely separate from their SSH access then perhaps\nUse sampling to reduce alert volume Sampling is the simplest and most common way to tune assurance alerts. Airport security doesn‚Äôt screen every single traveller. The government doesn‚Äôt audit every single person‚Äôs taxes. Instead, they choose a sample of people to check.\nThere‚Äôs definitely a risk to sampling‚Äîthere‚Äôs a chance you‚Äôll miss some alerts for actual malicious things‚Äîbut that‚Äôs a tradeoff you need to make. But, sampling is nice because the tradeoff you‚Äôre making is very clear‚Äîif you review 25% of the alerts, you‚Äôve introduced a 75% chance of missing a real attacker.\nIn many cases sampling is worth the risk. If you‚Äôve got other detection rules that can catch the compromise even if you missed the initial assurance alert, sampling is probably a good choice. Likewise, if an attacker is going to trigger multiple assurance alerts then sampling is an excellent choice. Even if you only review 25% of alerts, if an attacker is going to generate 10 of them, you‚Äôve still got excellent chances of catching them.\n  Improving Noisy alerts üîá Sampling noisy alerts doesn‚Äôt really help: now on top of false-positives, you‚Äôve added false-negatives to the problem. The savings made by reducing alert volume are negated by making the alert even less likely to catch maliciousness.\nThe best way to improve a noisy alert is to reduce the false-positive rate. Simple! üôÑ\nUnfortunately, tactics for tuning noisy alerts are far beyond the scope of this post. Instead, I‚Äôll leave you with this thought: if the expected value of reviewing an alert is lower than the cost of reviewing it, perhaps the best option is to bin it?\n",
  "wordCount" : "1685",
  "inLanguage": "en",
  "datePublished": "2021-01-30T00:00:00Z",
  "dateModified": "2021-01-30T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Bradley Kemp"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://bradleyjkemp.dev/post/why-you-should-measure-more-than-just-false-positive-rate/"
  },
  "publisher": {
    "@type": "Person",
    "name": "bradleyjkemp",
    "logo": {
      "@type": "ImageObject",
      "url": "https://bradleyjkemp.dev/favicon.ico"
    }
  }
}
</script>



</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>
<noscript>
    <style type="text/css">
        .theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript>
<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://bradleyjkemp.dev" accesskey="h" title="bradleyjkemp (Alt + H)">bradleyjkemp</a>
            <span class="logo-switches">
                <span class="theme-toggle" title="(Alt + T)">
                    <a id="theme-toggle" accesskey="t">
                        <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                            fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                            stroke-linejoin="round">
                            <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                        </svg>
                        <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                            fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                            stroke-linejoin="round">
                            <circle cx="12" cy="12" r="5"></circle>
                            <line x1="12" y1="1" x2="12" y2="3"></line>
                            <line x1="12" y1="21" x2="12" y2="23"></line>
                            <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                            <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                            <line x1="1" y1="12" x2="3" y2="12"></line>
                            <line x1="21" y1="12" x2="23" y2="12"></line>
                            <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                            <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                        </svg>
                    </a>
                </span>
                
            </span>
        </div>
        <ul class="menu" id="menu" onscroll="menu_on_scroll()"></ul>
    </nav>
</header>

    <main class="main">

<article class="post-single">
  <header class="post-header">
    <h1 class="post-title">
      Why you should measure more than just false-positive rate
    </h1>
    <div class="post-description">
      
    </div>
    <div class="post-meta">

January 30, 2021&nbsp;¬∑&nbsp;8 min&nbsp;¬∑&nbsp;Bradley Kemp

    </div>
  </header> 

  <div class="post-content">
<p>Other titles:</p>
<ul>
<li>Why you need to measure an alert&rsquo;s benign rate, not just false-positive rate</li>
<li>Why you need to measure benign rate, not just false-positive rate for alerts</li>
<li>Not all false-positive alerts are bad. Why you need to measure malicious-rate too.</li>
<li>Not all high false-positive rate alerts are noisy</li>
</ul>
<p>False-positive rate is a great metric to use while developing detection rules but, once a rule is in production, things get more complicated.</p>
<p>But before we go any further, why measure detection rule performance in the first place?
Unless you&rsquo;ve got an unlimited budget for SOC analysts, you need to decide which security alerts are valuable enough to review and which you&rsquo;re going to ignore.</p>
<p>You might be making this decision explicitly (just dropping unreviewed alerts at the end of the day) or implicitly</p>
<p>Even if you&rsquo;re thinking &ldquo;but we don&rsquo;t ignore any alerts, we review them all!&rdquo;,
However, I&rsquo;m sure there&rsquo;s more detection rules you could add and if you&rsquo;re choosing not to, you&rsquo;re choosing to ignore those alerts.
There&rsquo;s always more detection rules you can add and if you&rsquo;re choosing to skip these new rules, you&rsquo;re choosing to ignore these alerts.</p>
<p>The hard part of detection engineering is tuning alerts so reviewing them is a valuable use of time.
Every alert has an attached opportunity cost.
By choosing to review it, you&rsquo;re implicitly choosing <em>not</em> to review another alert.</p>
<p>It&rsquo;s therefore vital to be able to understand which alerts are valuable, which need tuning, and which just need to be scrapped because they&rsquo;re a time sink.
How? Metrics.</p>
<h2 id="the-problem-with-only-measuring-false-positive-rate">The problem with only measuring false-positive rate<a hidden class="anchor" aria-hidden="true" href="#the-problem-with-only-measuring-false-positive-rate">#</a></h2>
<p>Let&rsquo;s take an example detection rule that alerts whenever someone SSH&rsquo;s into a production server&mdash;the goal being to catch an attacker stealing or tampering with production data.
Hopefully you don&rsquo;t have attackers accessing your servers on a regular basis&mdash;if so, this post isn&rsquo;t for you&mdash;so most of the alerts are going to be when an on-call engineer needs to SSH into production to fix an incident.
An alert reviewer handles this by checking that, yes, there was an ongoing incident and the engineer that triggered the alert was responding.</p>
<p>But, how should they close the alert?
There&rsquo;s no impact so perhaps they should mark it as a false-positive?
If they do, your stats will show this alert having an almost 100% false-positive rate.</p>
<p>In comparison, lets imagine a detection rule that alerts on newly registered domain names which are similar to your company&rsquo;s name.
Depending on your company this could generate lots of alerts for domains which are closed as obviously harmless false-positives. A rule this simple is not going to be useful for Apple or Three or any other noun-named company.
If that&rsquo;s you, your stats will show that this alert also has a very high false-positive rate.</p>
<p>But something&rsquo;s wrong here.
The SSH alert actually does provide some value (verifying that on-call engineers aren&rsquo;t abusing their systems access) whereas the harmless domain name alerts are providing no value.
Despite this, just scoring them on false-positive rate could make them look equally bad.</p>
<p>// The reason is because false-positive vs true-positive is a false dichotomy&mdash;we need more &ldquo;dimensions&rdquo; to our rating.</p>
<h2 id="measuring-a-second-dimension-maliciousness">Measuring a second dimension: maliciousness<a hidden class="anchor" aria-hidden="true" href="#measuring-a-second-dimension-maliciousness">#</a></h2>
<p>Is a detection rule&rsquo;s goal to detect security incidents?
Actually no, not really.
That&rsquo;s the goal of an entire suite of detections rules plus a team who review the alerts.
An individual rule should have an extremely specific aim for what it detects, for example:</p>
<ul>
<li>Attackers are likely to steal data so alert on SSH access to our production servers.</li>
<li>Phishing sites are usually hosted on lookalike domains so alert on newly registered domains which are similar to our company&rsquo;s name.</li>
<li>No legitimate users should be accessing a honeypot fileserver so alert on any interaction with it.</li>
</ul>
<p>Whether an alert fired correctly (i.e. in line with the rule&rsquo;s aim) is entirely separate from whether it detected malicious behaviour.</p>
<p>If your honeypot fileserver downloads a software update and an alert fires, that&rsquo;s a false-positive: a self-update shouldn&rsquo;t have been detected as a user interacting with the honeypot.</p>
<p>But, the alert that fires when a curious user stumbles across the honeypot fileserver is a <strong>true</strong>-positive.
While the behaviour may not have been malicious, the alert did fire correctly.</p>
<p>So what happens if we separately measure alert correctness and maliciousness?
You get something like this üëáüèª</p>
<p><img src="true-positive-malicious-axes.png" alt="TODO"></p>
<p>Unsurprisingly, we get a much more nuanced picture.
No longer the false dichotomy between high-signal alert and noisy alert.
Instead a third type of alerts appears: the assurance alert.</p>
<p>Let&rsquo;s go over the different quadrants.</p>
<h3 id="-high-signal-alerts---todo-alerts-or-rules">‚ÜóÔ∏è High signal alerts üö® // TODO: alerts or rules?<a hidden class="anchor" aria-hidden="true" href="#-high-signal-alerts---todo-alerts-or-rules">#</a></h3>
<p>This one should be obvious, detection rules with high true-positive rate and high malicious rate are your gold standard.
They produce really high signal alerts that you definitely shouldn&rsquo;t be ignoring.</p>
<p>High signal alerts are going to include:</p>
<ul>
<li>The catastrophic stuff e.g. a binary is running whose hash matches known malware.</li>
<li>// TODO</li>
<li>The impossible stuff e.g. a honeypot gets triggered on your internal network.</li>
</ul>

<style>
  #callout {
    background: var(--code-bg);
    padding: 1.5em 1.25em;
    border-radius: 3px;
    display: flex;
    flex-direction: row;
    margin-bottom: 20px;
  }
  #callout-inner {
    margin-left: 1em;
  }
  @media (max-width: 767px) {
    #callout {
    padding: 1.5em 0.75em 1.5em 0.6em;
    }
    #callout-inner {
      margin-left: 0.5em;
    }
  }
</style>
<div id="callout" style="">
  <div>üçØ</div>
	<div id="callout-inner">
    Honeypots are a great example of high signal alerts with really low false-positive rates. Read my previous post to find out <a href="https://bradleyjkemp.dev/post/how-intrusion-detection-honeypots-work-so-well/"><em>how</em> honeypots work so well</a>.
  </div>
</div>
<h3 id="-assurance-alerts-">‚ÜòÔ∏è Assurance alerts ‚úÖ<a hidden class="anchor" aria-hidden="true" href="#-assurance-alerts-">#</a></h3>
<p>Detection rules with a high true-positive rate but high benign rate are &ldquo;assurance&rdquo; alerts.</p>
<p>Think of all the &ldquo;you&rsquo;ve signed in on a new device&rdquo; or &ldquo;the email address on your account has been changed&rdquo; emails you&rsquo;ve received.
They&rsquo;re always accurate (true positives) but they&rsquo;re also almost always benign because you&rsquo;ve triggered them yourself.
These are assurance alerts.</p>
<p>The purpose of assurance alerts isn&rsquo;t to catch an attacker every time the alert fires, it&rsquo;s to give you confidence that an attacker can&rsquo;t do something without you knowing.</p>
<p>Assurance alerts are going to include things like:</p>
<ul>
<li>Someone has used a break-glass procedure, only intended for use during incidents. You need to verify it&rsquo;s been used appropriately.</li>
<li>Someone has been granted administrative permissions. You need to check they&rsquo;re supposed to have these new, powerful permissions.</li>
<li>A binary has done something weird TODO</li>
</ul>
<h3 id="-noisy-alerts-">‚ÜôÔ∏è Noisy alerts üîá<a hidden class="anchor" aria-hidden="true" href="#-noisy-alerts-">#</a></h3>
<p>Detection rules with a high false-positive rate and a high benign rate are the classic &ldquo;noisy&rdquo; alert.</p>
<p>Noisy alerts just plain suck.
They&rsquo;re not worth the time spent reviewing them.</p>
<h3 id="-dumb-luck-alerts-">‚ÜñÔ∏è Dumb luck alerts üçÄ<a hidden class="anchor" aria-hidden="true" href="#-dumb-luck-alerts-">#</a></h3>
<p>The fourth quadrant, with a high false-positive rate and miraculously high malicious rate, probably doesn&rsquo;t exist.</p>
<p>If you have a detection rule that regularly mis-fires but on investigation you <em>still</em> find malicious behaviour then either:</p>
<ul>
<li>You need to stop reading this post and go evict the 1000 different attackers you have in your system.</li>
<li>You&rsquo;re investigating alerts <em>way</em> too deeply. Go update LinkedIn with your new title &ldquo;Threat Hunter&rdquo; and collect a 50% pay rise.</li>
</ul>
<h2 id="using-these-metrics-to-improve-our-alerts">Using these metrics to improve our alerts<a hidden class="anchor" aria-hidden="true" href="#using-these-metrics-to-improve-our-alerts">#</a></h2>
<p>So how do we use these metrics to make better decisions about which alerts to review?</p>
<h3 id="improving-assurance-alerts-">Improving Assurance alerts ‚úÖ<a hidden class="anchor" aria-hidden="true" href="#improving-assurance-alerts-">#</a></h3>
<p>Assurance alerts are a sore spot.
Although they provide some value, reviewing them feels very unproductive&mdash;they mostly just require verifying that the event was expected.</p>
<p>However, it&rsquo;s a tough decision to get rid of them.
These alerts exist because the consequences of a true-positive, malicious alert are very bad.
Personally, would you be comfortable not being notified whenever your account was signed into on a new device?</p>
<h4 id="use-mfa-to-shift-the-burden">Use MFA to shift the burden<a hidden class="anchor" aria-hidden="true" href="#use-mfa-to-shift-the-burden">#</a></h4>
<p>A lot of the pain of assurance alerts arises because the people reviewing the alerts don&rsquo;t have the same context as the people causing the alerts.</p>
<p>When reviewing an alert for an on-call engineer accessing to a production server, the reviewer has to go work out: what incident might this be related to? does that incident actually require accessing production?
While these answers are obvious to the person who triggered the alert, they&rsquo;re not so easy for the alert reviewer.</p>
<p>It&rsquo;d be great if the person generating the alert could also review it.
They&rsquo;ve got all the context and so can easily affirm, yes I did just do X.
Obviously, this needs to be done carefully&mdash;it&rsquo;s no use if an attacker can SSH into production and then just close the alert themself.</p>
<p>That&rsquo;s where multi-factor authentication can help.
If the on-call engineer has an authentication factor that&rsquo;s entirely separate from their SSH access then perhaps</p>
<h4 id="use-sampling-to-reduce-alert-volume">Use sampling to reduce alert volume<a hidden class="anchor" aria-hidden="true" href="#use-sampling-to-reduce-alert-volume">#</a></h4>
<p>Sampling is the simplest and most common way to tune assurance alerts.
Airport security doesn&rsquo;t screen every single traveller. The government doesn&rsquo;t audit every single person&rsquo;s taxes.
Instead, they choose a sample of people to check.</p>
<p>There&rsquo;s definitely a risk to sampling&mdash;there&rsquo;s a chance you&rsquo;ll miss some alerts for actual malicious things&mdash;but that&rsquo;s a tradeoff you need to make.
But, sampling is nice because the tradeoff you&rsquo;re making is very clear&mdash;if you review 25% of the alerts, you&rsquo;ve introduced a 75% chance of missing a real attacker.</p>
<p>In many cases sampling is worth the risk.
If you&rsquo;ve got other detection rules that can catch the compromise even if you missed the initial assurance alert, sampling is probably a good choice.
Likewise, if an attacker is going to trigger multiple assurance alerts then sampling is an excellent choice.
Even if you only review 25% of alerts, if an attacker is going to generate 10 of them, you&rsquo;ve still got excellent chances of catching them.</p>
<figure>
    <img src="swiss_cheese_model.png" width="75%"/> 
</figure>

<h3 id="improving-noisy-alerts-">Improving Noisy alerts üîá<a hidden class="anchor" aria-hidden="true" href="#improving-noisy-alerts-">#</a></h3>
<p>Sampling noisy alerts doesn&rsquo;t really help: now on top of false-positives, you&rsquo;ve added false-negatives to the problem.
The savings made by reducing alert volume are negated by making the alert even less likely to catch maliciousness.</p>
<p>The best way to improve a noisy alert is to reduce the false-positive rate. Simple! üôÑ</p>
<p>Unfortunately, tactics for tuning noisy alerts are far beyond the scope of this post.
Instead, I&rsquo;ll leave you with this thought: if the expected value of reviewing an alert is lower than the cost of reviewing it, perhaps the best option is to bin it?</p>

</div>
  <footer class="post-footer">



<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share Why you should measure more than just false-positive rate on twitter"
        href="https://twitter.com/intent/tweet/?text=Why%20you%20should%20measure%20more%20than%20just%20false-positive%20rate&amp;url=https%3a%2f%2fbradleyjkemp.dev%2fpost%2fwhy-you-should-measure-more-than-just-false-positive-rate%2f&amp;hashtags=">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Why you should measure more than just false-positive rate on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fbradleyjkemp.dev%2fpost%2fwhy-you-should-measure-more-than-just-false-positive-rate%2f&amp;title=Why%20you%20should%20measure%20more%20than%20just%20false-positive%20rate&amp;summary=Why%20you%20should%20measure%20more%20than%20just%20false-positive%20rate&amp;source=https%3a%2f%2fbradleyjkemp.dev%2fpost%2fwhy-you-should-measure-more-than-just-false-positive-rate%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Why you should measure more than just false-positive rate on reddit"
        href="https://reddit.com/submit?url=https%3a%2f%2fbradleyjkemp.dev%2fpost%2fwhy-you-should-measure-more-than-just-false-positive-rate%2f&title=Why%20you%20should%20measure%20more%20than%20just%20false-positive%20rate">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Why you should measure more than just false-positive rate on facebook"
        href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fbradleyjkemp.dev%2fpost%2fwhy-you-should-measure-more-than-just-false-positive-rate%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Why you should measure more than just false-positive rate on whatsapp"
        href="https://api.whatsapp.com/send?text=Why%20you%20should%20measure%20more%20than%20just%20false-positive%20rate%20-%20https%3a%2f%2fbradleyjkemp.dev%2fpost%2fwhy-you-should-measure-more-than-just-false-positive-rate%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Why you should measure more than just false-positive rate on telegram"
        href="https://telegram.me/share/url?text=Why%20you%20should%20measure%20more%20than%20just%20false-positive%20rate&amp;url=https%3a%2f%2fbradleyjkemp.dev%2fpost%2fwhy-you-should-measure-more-than-just-false-positive-rate%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
</div>

  </footer>
<link href="//cdn-images.mailchimp.com/embedcode/classic-10_7.css" rel="stylesheet" type="text/css">
<style type="text/css">
    #mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }
     
</style>
<div id="mc_embed_signup">
    <form action="https://dev.us7.list-manage.com/subscribe/post?u=d9ccca3191f132a65b2088839&amp;id=3593d3bd31" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
        <div id="mc_embed_signup_scroll">
            <h2>Subscribe to get an email for every new post</h2>
            <div class="mc-field-group">
                <label for="mce-EMAIL">Email Address </label>
                <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL">
            </div>
            <div id="mce-responses" class="clear">
                <div class="response" id="mce-error-response" style="display:none"></div>
                <div class="response" id="mce-success-response" style="display:none"></div>
            </div>    
            <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_d9ccca3191f132a65b2088839_3593d3bd31" tabindex="-1" value=""></div>
            <div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
        </div>
    </form>
</div>


</article>
    </main><footer class="footer">
    <span>&copy; 2021 <a href="https://bradleyjkemp.dev">bradleyjkemp</a></span>
    <span>&middot;</span>
    <span>Powered by <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a></span>
    <span>&middot;</span>
    <span>Theme <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a></span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)">
    <button class="top-link" id="top-link" type="button" accesskey="g">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6">
            <path d="M12 6H0l6-6z" />
        </svg>
    </button>
</a>



<script defer src="https://bradleyjkemp.dev/assets/js/highlight.min.27cd435cc9ed6abb4b496581b151804f79f366c412620272bb94e2f5f598ebcc.js" integrity="sha256-J81DXMntartLSWWBsVGAT3nzZsQSYgJyu5Ti9fWY68w="
    onload="hljs.initHighlightingOnLoad();"></script>
<script>
    window.onload = function () {
        if (localStorage.getItem("menu-scroll-position")) {
            document.getElementById('menu').scrollLeft = localStorage.getItem("menu-scroll-position");
        }
    }
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                behavior: "smooth"
            });
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.replaceState(null, null, `#${id}`);
            }
        });
    });
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

    function menu_on_scroll() {
        localStorage.setItem("menu-scroll-position", document.getElementById('menu').scrollLeft);
    }

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>

</body>

</html>
