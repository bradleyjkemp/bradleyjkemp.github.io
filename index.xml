<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>bradleyjkemp</title>
    <link>https://bradleyjkemp.dev/</link>
    <description>Recent content on bradleyjkemp</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 08 Mar 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://bradleyjkemp.dev/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Simple A/B testing with Caddy and Plausible Analytics</title>
      <link>https://bradleyjkemp.dev/post/simple-a/b-testing-with-caddy-and-plausible-analytics/</link>
      <pubDate>Mon, 08 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://bradleyjkemp.dev/post/simple-a/b-testing-with-caddy-and-plausible-analytics/</guid>
      <description>This post first appeared on the QueryCal technical blog.
 A/B testing is a life saver for a solo SaaS developer. While it&amp;rsquo;s hard to predict whether a 14-day or 1-month trial is going to get a better signup rate, it&amp;rsquo;s really simple to test: show half of people the 14-day button and the other half the 1-month button and just measure the click-through rate.
There&amp;rsquo;s loads of tools out there to help you do this, but rule #1 of running a micro-SaaS like QueryCal is to keep your technology stack simple&amp;mdash;it&amp;rsquo;s better to focus your time on features not integrating a bunch of different technologies.</description>
    </item>
    
    <item>
      <title>Assurance alerts: when measuring false-positive rate can be misleading</title>
      <link>https://bradleyjkemp.dev/post/assurance-alerts-when-measuring-false-positive-rate-can-be-misleading/</link>
      <pubDate>Mon, 08 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://bradleyjkemp.dev/post/assurance-alerts-when-measuring-false-positive-rate-can-be-misleading/</guid>
      <description>Nobody likes alerts that feel like a waste of time to review. But, how do you tell whether an alert is actually a waste of time?
The go-to metric to use is false-positive rate&amp;mdash;if an alert has high a false-positive rate then it&amp;rsquo;s &amp;ldquo;noisy&amp;rdquo; and might be getting rid of. But, trying to distill the performance of an alert down to a single number is hard and false-positive rate might be a particularly bad choice.</description>
    </item>
    
    <item>
      <title>Spending your security goodwill budget wisely</title>
      <link>https://bradleyjkemp.dev/post/spending-your-security-goodwill-budget-wisely/</link>
      <pubDate>Mon, 04 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://bradleyjkemp.dev/post/spending-your-security-goodwill-budget-wisely/</guid>
      <description>Making users more secure generally means annoying them. Whether it&amp;rsquo;s making them carry a hardware security key or just enforcing a short screensaver timeout, changing how people go about their work is annoying&amp;mdash;and an annoyed user is not a secure user.
The effectiveness of a lot of security controls relies on the user cooperating. If they get frustrated with all the barriers and friction between them and doing their actual job, they might just find ways around the controls&amp;mdash;their shortened screensaver timeout is soon &amp;ldquo;fixed&amp;rdquo; with a keep-awake app and now they&amp;rsquo;re less secure than they were before.</description>
    </item>
    
    <item>
      <title>How intrusion detection honeypots work so well</title>
      <link>https://bradleyjkemp.dev/post/how-intrusion-detection-honeypots-work-so-well/</link>
      <pubDate>Tue, 08 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bradleyjkemp.dev/post/how-intrusion-detection-honeypots-work-so-well/</guid>
      <description>Intrusion detection honeypots are just plain cool. They&amp;rsquo;re incredibly simple to run and give you extremely accurate alerts about intruders in your systems.
A honeypot can be as simple as a fake server inside your network that alerts if anyone connects to it. There&amp;rsquo;s no reason to intentionally connect to this bogus server, so any attempts are probably an attacker already inside your network.
Unfortunately, that&amp;rsquo;s about as far as most people get with them.</description>
    </item>
    
    <item>
      <title>Snapshot Testing Is Hard -- Pitfalls To Avoid</title>
      <link>https://bradleyjkemp.dev/post/snapshot-testing-is-hard-pitfalls-to-avoid/</link>
      <pubDate>Tue, 19 Dec 2017 12:21:26 +0000</pubDate>
      
      <guid>https://bradleyjkemp.dev/post/snapshot-testing-is-hard-pitfalls-to-avoid/</guid>
      <description>Snapshot testing is an extremely fast way to add regression testing to an existing project. You simply take some example inputs and then snapshot the resulting outputs. From then on, you can have a high degree of confidence that any changes you make have not affected backwards compatibility (as this would have been detected as a change in a snapshot).
However there are many pitfalls you can run into as I found when writing cupaloy, a snapshot testing library for Go.</description>
    </item>
    
  </channel>
</rss>
